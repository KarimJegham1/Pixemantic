{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a69ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics==8.0.43 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (8.0.43)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (1.23.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (10.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (4.64.0)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (2.17.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (1.4.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (0.11.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (5.8.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: wheel>=0.38.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (0.43.0)\n",
      "Requirement already satisfied: sentry-sdk in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from ultralytics==8.0.43) (1.40.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.43) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.43) (2021.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.43) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.43) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.43) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.43) (2024.7.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (1.51.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (3.3.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (61.2.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->ultralytics==8.0.43) (2.0.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics==8.0.43) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.0.43) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->ultralytics==8.0.43) (3.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install  ultralytics==8.0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84950602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\topinformatique\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d874fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/TOPINFORMATIQUE/Desktop/test3/valid\n",
      "Initialised with 42 image(s) found.\n",
      "Output directory set to C:/Users/TOPINFORMATIQUE/Desktop/test3/valid\\fallen.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D957064070>: 100%|███| 4/4 [00:00<00:00, 31.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D957057700>: 100%|█| 42/42 [00:00<00:00, 95.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D957052610>: 100%|█| 42/42 [00:00<00:00, 95.87 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 78 image(s) found.\n",
      "Output directory set to C:/Users/TOPINFORMATIQUE/Desktop/test3/valid\\standing.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D957022C10>: 100%|███| 4/4 [00:00<00:00, 27.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D95706C5E0>: 100%|█| 78/78 [00:00<00:00, 86.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=640x640 at 0x1D95706A820>: 100%|█| 78/78 [00:00<00:00, 93.84 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "import os\n",
    "import shutil\n",
    "from shutil import SameFileError\n",
    "def augment_data(pth, num_samples, augment_factor=2):\n",
    "    # Iterate through sub-directories\n",
    "    for subdir in os.listdir(pth):\n",
    "        subdir_path = os.path.join(pth, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            output_dir = subdir_path  # Specify the output directory\n",
    "            os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "            # Create Augmentor pipeline for each sub-directory\n",
    "            pipeline = Augmentor.Pipeline(subdir_path, output_directory=output_dir)\n",
    "\n",
    "            # Define augmentations\n",
    "            pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "            pipeline.flip_left_right(probability=0.7)\n",
    "            pipeline.zoom_random(probability=0.3, percentage_area=0.8)\n",
    "            pipeline.flip_top_bottom(probability=0.5)\n",
    "            print(num_samples)\n",
    "            # Number of samples per original image\n",
    "            pipeline.sample(num_samples)\n",
    "            \n",
    "            # Further augment the data by applying the pipeline multiple times\n",
    "            for i in range(augment_factor - 1):\n",
    "                pipeline.process()\n",
    "\n",
    "            # Copy original images to the output directory\n",
    "            original_images = os.listdir(subdir_path)\n",
    "            for img in original_images:\n",
    "                try:\n",
    "                    shutil.copy(os.path.join(subdir_path, img), output_dir)\n",
    "                except SameFileError:\n",
    "                    continue\n",
    "\n",
    "num_samples_per_image = 4 # Number of samples to generate for each original image\n",
    "augment_factor = 3\n",
    "path='C:/Users/TOPINFORMATIQUE/Desktop/test3/valid'\n",
    "print(path)\n",
    "# Make sure to define the 'path' variable with the correct path before calling the function\n",
    "augment_data(path, num_samples=num_samples_per_image, augment_factor=augment_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c6f81f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1700 images belonging to 2 classes.\n",
      "Found 368 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Paths to your dataset\n",
    "train_dir = 'C:\\\\Users\\\\TOPINFORMATIQUE\\\\Desktop\\\\test3\\\\train'\n",
    "validation_dir = 'C:\\\\Users\\\\TOPINFORMATIQUE\\\\Desktop\\\\test3\\\\valid'\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,              # Normalize images\n",
    "    rotation_range=20,           # Data augmentation\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # Resize images to fit model input\n",
    "    batch_size=64,\n",
    "    class_mode='binary'      # Binary classification\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc00bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOPINFORMATIQUE\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 4s/step - accuracy: 0.5059 - loss: 5.6507 - val_accuracy: 0.6467 - val_loss: 0.6012\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 4s/step - accuracy: 0.6217 - loss: 0.6460 - val_accuracy: 0.3696 - val_loss: 1.1353\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.5995 - loss: 0.6746 - val_accuracy: 0.6957 - val_loss: 0.5793\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.7531 - loss: 0.5520 - val_accuracy: 0.6522 - val_loss: 0.5852\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3s/step - accuracy: 0.7569 - loss: 0.5290 - val_accuracy: 0.7065 - val_loss: 0.5416\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.7337 - loss: 0.5211 - val_accuracy: 0.7120 - val_loss: 0.5191\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.7652 - loss: 0.4884 - val_accuracy: 0.7310 - val_loss: 0.4896\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.8108 - loss: 0.4516 - val_accuracy: 0.8098 - val_loss: 0.4214\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.8088 - loss: 0.4388 - val_accuracy: 0.7962 - val_loss: 0.4155\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8505 - loss: 0.4102 - val_accuracy: 0.8859 - val_loss: 0.3529\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8262 - loss: 0.4050 - val_accuracy: 0.8995 - val_loss: 0.3287\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8377 - loss: 0.3899 - val_accuracy: 0.7174 - val_loss: 0.4597\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8320 - loss: 0.3843 - val_accuracy: 0.9239 - val_loss: 0.2921\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8345 - loss: 0.3879 - val_accuracy: 0.7636 - val_loss: 0.3957\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8652 - loss: 0.3401 - val_accuracy: 0.7065 - val_loss: 0.4627\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8707 - loss: 0.3225 - val_accuracy: 0.8342 - val_loss: 0.3363\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.8868 - loss: 0.3037 - val_accuracy: 0.8505 - val_loss: 0.3271\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9012 - loss: 0.2908 - val_accuracy: 0.9457 - val_loss: 0.2192\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8845 - loss: 0.2996 - val_accuracy: 0.6467 - val_loss: 0.5948\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.8675 - loss: 0.3111 - val_accuracy: 0.8696 - val_loss: 0.2972\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8868 - loss: 0.2851 - val_accuracy: 0.9049 - val_loss: 0.2607\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9162 - loss: 0.2274 - val_accuracy: 0.7473 - val_loss: 0.4106\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8664 - loss: 0.2951 - val_accuracy: 0.8859 - val_loss: 0.2780\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9219 - loss: 0.2231 - val_accuracy: 0.9538 - val_loss: 0.1757\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9244 - loss: 0.2237 - val_accuracy: 0.9049 - val_loss: 0.2528\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9247 - loss: 0.2154 - val_accuracy: 0.9103 - val_loss: 0.2421\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9283 - loss: 0.1975 - val_accuracy: 0.8913 - val_loss: 0.2690\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9187 - loss: 0.2124 - val_accuracy: 0.9158 - val_loss: 0.2223\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.9259 - loss: 0.2024 - val_accuracy: 0.9701 - val_loss: 0.1247\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.9335 - loss: 0.1938 - val_accuracy: 0.9103 - val_loss: 0.2285\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 4s/step - accuracy: 0.9500 - loss: 0.1805 - val_accuracy: 0.9266 - val_loss: 0.1928\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9431 - loss: 0.1710 - val_accuracy: 0.9620 - val_loss: 0.1285\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.9348 - loss: 0.1850 - val_accuracy: 0.9158 - val_loss: 0.2073\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 4s/step - accuracy: 0.9435 - loss: 0.1711 - val_accuracy: 0.9293 - val_loss: 0.1921\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.9607 - loss: 0.1475 - val_accuracy: 0.9293 - val_loss: 0.1863\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9575 - loss: 0.1424 - val_accuracy: 0.9538 - val_loss: 0.1289\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 4s/step - accuracy: 0.9483 - loss: 0.1522 - val_accuracy: 0.9212 - val_loss: 0.1910\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 4s/step - accuracy: 0.9374 - loss: 0.1636 - val_accuracy: 0.9321 - val_loss: 0.1808\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.9494 - loss: 0.1615 - val_accuracy: 0.9457 - val_loss: 0.1614\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9376 - loss: 0.1594 - val_accuracy: 0.9457 - val_loss: 0.1385\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 4s/step - accuracy: 0.9648 - loss: 0.1336 - val_accuracy: 0.9701 - val_loss: 0.0928\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 4s/step - accuracy: 0.9474 - loss: 0.1370 - val_accuracy: 0.9864 - val_loss: 0.0726\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 3s/step - accuracy: 0.9480 - loss: 0.1564 - val_accuracy: 0.9375 - val_loss: 0.1690\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.9659 - loss: 0.1212 - val_accuracy: 0.9049 - val_loss: 0.2052\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 3s/step - accuracy: 0.9530 - loss: 0.1386 - val_accuracy: 0.9864 - val_loss: 0.0533\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.9356 - loss: 0.1580 - val_accuracy: 0.7636 - val_loss: 0.4614\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9282 - loss: 0.1824 - val_accuracy: 0.9674 - val_loss: 0.0988\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9461 - loss: 0.1555 - val_accuracy: 0.9810 - val_loss: 0.0667\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.9262 - loss: 0.1693 - val_accuracy: 0.9755 - val_loss: 0.0772\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.9634 - loss: 0.1054 - val_accuracy: 0.9375 - val_loss: 0.1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('resnet50_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63f4cec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('resnet50_finetuned.h5')\n",
    "\n",
    "# Classify a new image\n",
    "def classify_image(image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0) / 255.0\n",
    "    prediction = model.predict(image)\n",
    "    return 'standing' if prediction[0][0] > 0.5 else 'fallen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "776c557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "standing\n"
     ]
    }
   ],
   "source": [
    "result = classify_image('C:/Users/TOPINFORMATIQUE/Desktop/fall-labeled/test/images/image_246_jpg.rf.87fddb38ee3a41713bea90274a21868c.jpg')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33da90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
